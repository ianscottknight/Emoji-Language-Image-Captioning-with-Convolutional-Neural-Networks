import json
import collections
from PIL import Image
import os
import torch 
import torch.nn as nn
import torch.utils.data as data


### Hyper parameters
NUM_EPOCHS = 40
BATCH_SIZE = 100
LR = 0.0001


EMOJI_CAPTIONS_TRAIN_FILE = 'annotations/captions_train.json'
EMOJI_CAPTIONS_TEST_FILE = 'annotations/captions_val.json'

id_to_emojis_dict = {}

with open(EMOJI_CAPTIONS_TRAIN_FILE) as f:
    d = json.load(f)
    for image_id in d: 
        id_to_emojis_dict[int(image_id)] = [emoji for emoji, score in d[str(image_id)][1]]
        
with open(EMOJI_CAPTIONS_TEST_FILE) as f:
    d = json.load(f)
    for image_id in d: 
        id_to_emojis_dict[int(image_id)] = [emoji for emoji, score in d[str(image_id)][1]]

classes = []
class_count_dict = collections.defaultdict(int)

for key in id_to_emojis_dict.keys():
    for emoji in id_to_emojis_dict[key]: 
        if emoji not in classes: 
            classes.append(emoji)
        class_count_dict[emoji] += 1
        
count = collections.Counter(class_count_dict)

### 320 classes have 10 or fewer instances
### 536 classes have 50 or fewer instances
### 628 classes have 100 or fewer instances


### Remove rare emojis

emoji_classes = [key for key in count.keys() if count[key] > 100]

for key in id_to_emojis_dict.keys():
    yes_list = []
    for emoji in id_to_emojis_dict[key]: 
        if emoji in emoji_classes:
            yes_list.append(emoji)
    if len(yes_list) < 5: 
        if len(yes_list) == 0:
            yes_list = sorted(count, key=count.get, reverse=True)[:5] # Just make yes_list into the most common emojis
        else:
            for i in range(5 - len(yes_list)):
                yes_list.append(yes_list[i])
    id_to_emojis_dict[key] = yes_list


### Condense emojis with similar/same meanings to just one emoji (per meaning)

categories_to_keep = [
    
    ['ðŸ‘¨', 'ðŸ‘¨ðŸ»', 'ðŸ‘¨ðŸ¿', 'ðŸ‘±ðŸ¿'], # man
    ['ðŸ‘©', 'ðŸ‘©ðŸ»'], # woman
    ['ðŸ‘¦', 'ðŸ‘¦ðŸ»'], # boy 
    ['ðŸ‘§', 'ðŸ‘§ðŸ»'], # girl
    ['ðŸ‘¶', 'ðŸ‘¶ðŸ»', 'ðŸ¼'], # baby
    ['ðŸ‘ª', 'ðŸ‘¨\u200dðŸ‘©\u200dðŸ‘¦\u200dðŸ‘¦', 'ðŸ‘¨\u200dðŸ‘©\u200dðŸ‘§\u200dðŸ‘§', \
                'ðŸ‘©\u200dðŸ‘©\u200dðŸ‘¦\u200dðŸ‘¦', 'ðŸ‘©\u200dðŸ‘©\u200dðŸ‘§\u200dðŸ‘§', 'ðŸ‘¨\u200dðŸ‘¨\u200dðŸ‘§\u200dðŸ‘§'], # family
    ['ðŸ‘¥', 'ðŸ‘«', 'ðŸ‘¬', 'ðŸ‘­', 'ðŸ’‘', 'ðŸ‘¨\u200dâ¤ï¸\u200dðŸ‘¨'], # group of people
    ['ðŸ‘®', 'ðŸ‘®ðŸ¿'], # police
    ['ðŸ„', 'ðŸ„ðŸ»', 'ðŸ„ðŸ¿'], # surfing
    ['âœˆï¸', 'ðŸ›¬', 'ðŸ›©'], # airplane
    ['ðŸ›', 'ðŸ›€'], # bathtub
    ['ðŸŽ', 'ðŸ´', 'ðŸ‡ðŸ¿', 'ðŸ‡', 'ðŸŽ '], # horse
    ['ðŸ“·', 'ðŸŽ¥', 'ðŸŽ¦', 'ðŸ“¹', 'ðŸ“½'], # camera
    ['ðŸšŽ', 'ðŸš', 'ðŸšŒ', 'ðŸš'], # bus
    ['ðŸšª', 'ðŸ”’'], # door/window
    ['â˜‚', 'â›±', 'ðŸŒ‚'], # umbrella
    ['ðŸ ', 'ðŸ¡', 'ðŸš', 'ðŸ˜' ], # house
    ['â°', 'â²', 'ðŸ•°', 'âŒšï¸'], # clock
    ['â›ªï¸', 'â›ª'], # church
    ['ðŸš´', 'ðŸšµ', 'ðŸš³'], # bike
    ['ðŸš˜', 'ðŸš—', 'ðŸš™'], # car
    ['ðŸ¶', 'ðŸ•', 'ðŸº'], # dog
    ['ðŸš›', 'ðŸšš'], # truck
    ['ðŸ›‹', 'ðŸ›'], # furniture
    ['â›¸', 'ðŸ’', 'ðŸ‘'], # ice-rink skating
    ['ðŸ’º', 'ðŸ“', 'ðŸ€'], # table/seat/sitting/bench
    ['ðŸ“ž', 'ðŸ“²', 'ðŸ“±', 'â˜Žï¸', 'ðŸ“µ'], # phone
    ['ðŸ®', 'ðŸ„'], # cow
    ['ðŸ±', 'ðŸˆ'], # cat
    ['ðŸ¦', 'ðŸ§'], # bird
    ['ðŸ­', 'ðŸ'], # mouse
    ['ðŸ»', 'ðŸ¯'], # bear
    ['ðŸˆ', 'ðŸ‰'], # football
    ['ðŸ“š', 'ðŸ“•', 'ðŸ“–'], # book/reading
    ['ðŸš–', 'ðŸš•'], # taxi
    ['ðŸ‘•', 'ðŸ‘”', 'ðŸ‘š'], # top/shirt
    ['ðŸ’¡', 'ðŸ•¯', 'ðŸ•Ž'], # light/lantern
    ['ðŸš¢', 'ðŸ›³', 'ðŸš¤', 'ðŸ›¥'], # boat
    ['ðŸ½', 'ðŸ´'], # plates/eating
    ['âš“', 'âš“ï¸'], # anchor
    ['ðŸ˜´', 'ðŸ’¤', ], # sleep
    ['ðŸ‘œ', 'ðŸ’¼', 'ðŸ‘'], # bag
    ['ðŸ”µ', 'ðŸ”¹'], # blue
    ['ðŸŽ¿', 'â›·'], # skiing
    ['ðŸª', 'ðŸ¬'], # store
    ['ðŸ¤µ', 'â™ ï¸'], # suit
    ['ðŸ—¿', 'ðŸ—½'], # statue
    ['âš ï¸', 'Â©ï¸', 'â˜£', 'ðŸš¸'], # sign
    ['ðŸš‚', 'ðŸš‰', 'ðŸš†', 'ðŸš‹'], # train
    ['ðŸš½', 'ðŸš¾', 'ðŸšº'], # bathroom
    ['â˜•', 'ðŸµ'], # cup
    ['âŒ¨', 'ðŸ–²', 'ðŸŽ¹'], # keyboard
    ['ðŸŽ', 'ðŸŽ£'], # kite
    ['ðŸ¸', 'ðŸ®'], # drink
    ['ðŸ—ƒ', 'â˜‘ï¸', 'ðŸ’'], # box
    ['ðŸš¶', 'ðŸš·'], # walking/standing
    ['ðŸŽ¶', 'ðŸŽ·', 'ðŸŽ»'], # music/band
    ['ðŸ»', 'ðŸ¶'], # alcohol
    ['ðŸŠ', 'âœ´ï¸', 'ðŸ”¸'], # orange
    ['ðŸŒ³', 'ðŸŒ²', 'ðŸ¦'], # tree/branch
    ['ðŸš®', 'ðŸš¯'], # trash/garbage
    ['ðŸŒ¼', 'ðŸŒ»'], # flower
    ['ðŸ•', 'â›ºï¸', 'ðŸŽª', 'â›ºï¸'], # tent
    ['ðŸ”', 'â›°'], # mountain
    ['ðŸ’µ', 'ðŸ’¶'], # paper/money
    ['ðŸ›„', 'ðŸ›…'], # luggage
    ['ðŸš¦', 'ðŸš¥'], # traffic light 
    ['ðŸ‘ž', 'ðŸ‘¡'] # shoe
    
]

for category in categories_to_keep: 
    for key in id_to_emojis_dict.keys():
        yes_list = []
        for emoji in id_to_emojis_dict[key]: 
            if emoji in category:
                yes_list.append(category[0])
            else:
                yes_list.append(emoji)
        id_to_emojis_dict[key] = yes_list


### Remove remaining emojis that are erroneous in their semantic translation from text (checked by human)

categories_to_remove = ['ðŸ‡©ðŸ‡¯', 'ðŸ‡®ðŸ‡²', 'ðŸ¨', 'ðŸ–±', 'ðŸ‘‹', 'ðŸ’…', 'ðŸ’ðŸ»', 'ðŸ’ðŸ½', 'ðŸ’ðŸ¿', \
                        'ðŸ™ðŸ¿', 'ðŸ™‡ðŸ¿', 'ðŸš£ðŸ¼', 'ðŸ‡§ðŸ‡§', 'ðŸ‡¬ðŸ‡º', 'ðŸ˜¦', 'ðŸ¤˜', 'ðŸ']

for key in id_to_emojis_dict.keys(): 
    yes_list = []
    for emoji in id_to_emojis_dict[key]:
        if emoji not in categories_to_remove: 
            yes_list.append(emoji)
    if len(yes_list) < 5: 
        if len(yes_list) == 0:
            yes_list = ['ðŸ‘¨', 'ðŸ‘©', 'ðŸ‘¦', 'ðŸ‘§', 'ðŸ‘¶'] # Just make yes_list into common, neutral emojis (very few instances)
        else:
            for i in range(5 - len(yes_list)):
                yes_list.append(yes_list[i])
    id_to_emojis_dict[key] = yes_list


emoji_classes = []

for value in id_to_emojis_dict.values():
    for emoji in value:
        if emoji not in emoji_classes:
            emoji_classes.append(emoji)


### Convert emojis to integers

emoji_to_int_dict = {}
int_to_emoji_dict = {}

for i, emoji in enumerate(emoji_classes):
    emoji_to_int_dict[emoji] = i # tokens between 0 and 326
    int_to_emoji_dict[i] = emoji

id_to_classes_dict = {}
for key in id_to_emojis_dict.keys():
    id_to_classes_dict[key] = [emoji_to_int_dict[emoji] for emoji in id_to_emojis_dict[key]]


class CocoCaptions(data.Dataset):

    def __init__(self, root, annFile, transform=None, target_transform=None):
        
        from pycocotools.coco import COCO
        self.root = os.path.expanduser(root)
        self.coco = COCO(annFile)
        self.ids = list(self.coco.imgs.keys())
        self.transform = transform
        self.target_transform = target_transform

    def __getitem__(self, index):

        coco = self.coco
        img_id = self.ids[index]
        ann_ids = coco.getAnnIds(imgIds=img_id)
        anns = coco.loadAnns(ann_ids)
        target = torch.tensor(id_to_classes_dict[img_id])

        path = coco.loadImgs(img_id)[0]['file_name']

        img = Image.open(os.path.join(self.root, path)).convert('RGB')
        if self.transform is not None:
            img = self.transform(img)

        if self.target_transform is not None:
            target = self.target_transform(target)

        return img_id, img, target

    def __len__(self):
        return len(self.ids)


### Convolutional neural network (two convolutional layers)
NUM_CLASSES = len(emoji_classes)

class ConvNet(nn.Module):
    def __init__(self, num_classes=NUM_CLASSES):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer3 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer4 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer5 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer6 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer7 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.AvgPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.5))
        self.fc1 = nn.Linear(2048, 5000)
        self.fc2 = nn.Linear(5000, 1000)
        self.fc3 = nn.Linear(1000, NUM_CLASSES)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.layer5(out)
        out = self.layer6(out)
        out = self.layer7(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc1(out)
        out = self.fc2(out)
        out = self.fc3(out)
        return out

